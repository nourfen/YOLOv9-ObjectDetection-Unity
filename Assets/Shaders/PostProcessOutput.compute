#pragma kernel CSMain

// Constants
cbuffer Constants
{
    float confidenceThreshold;
    int numDetections; // Should be 8400 in your case
    int numClasses;
    int imageWidth;
    int imageHeight;
}

// Input buffers (set by the CPU)
StructuredBuffer<float> outputTensor; // YOLO output tensor

// Output buffers (writeable, set by the CPU)
RWStructuredBuffer<float4> outputBoxes; // Stores [xMin, yMin, xMax, yMax] for each valid detection
RWStructuredBuffer<int> outputClasses; // Stores the class index for each valid detection
RWStructuredBuffer<float> outputScores; // Stores the confidence score for each valid detection

// Atomic counter for counting valid detections
RWByteAddressBuffer validDetectionCounter;

// Thread group size: 256 threads per group
[numthreads(256, 1, 1)]
void CSMain(uint3 id : SV_DispatchThreadID)
{
    uint detectionIndex = id.x;
    if (detectionIndex >= numDetections)
        return;

    // Define offsets for each attribute in column-major format
    uint centerXOffset = 0 * numDetections; // First 8400 values are centerX
    uint centerYOffset = 1 * numDetections; // Next 8400 values are centerY
    uint widthOffset = 2 * numDetections; // Next 8400 values are width
    uint heightOffset = 3 * numDetections; // Next 8400 values are height

    // Extract class scores and find the best one
    float maxClassScore = 0.0f;
    int classIndex = 0;
    for (int j = 0; j < numClasses; j++)
    {
        uint classOffset = (4 + j) * numDetections; // Class scores start after the 5 main attributes
        float classScore = outputTensor[classOffset + detectionIndex];
        if (classScore > maxClassScore)
        {
            maxClassScore = classScore;
            classIndex = j;
        }
    }

    // Calculate final confidence score
    if (maxClassScore < confidenceThreshold)
        return;

    // Extract bounding box in center format (centerX, centerY, width, height)
    float centerX = outputTensor[centerXOffset + detectionIndex];
    float centerY = outputTensor[centerYOffset + detectionIndex];
    float boxWidth = outputTensor[widthOffset + detectionIndex];
    float boxHeight = outputTensor[heightOffset + detectionIndex];

    // Convert bbox from center format to top-left and bottom-right
    float xMin = centerX - (boxWidth / 2.0f);
    float yMin = centerY - (boxHeight / 2.0f);
    float xMax = centerX + (boxWidth / 2.0f);
    float yMax = centerY + (boxHeight / 2.0f);
    
    // Apply scaling factors to adjust from 640x640 to actual image size
    //xMin *= scaleX;
    //xMax *= scaleX;
    //yMin *= scaleY;
    //yMax *= scaleY;

    // Adjust for image height (flip Y-axis)
    float flippedYMin = imageHeight - yMax;
    float flippedYMax = imageHeight - yMin;

    // Atomically increment the detection counter and get the valid index
    uint validIndex;
    validDetectionCounter.InterlockedAdd(0, 1, validIndex); // Atomically add 4 to the counter

    // Write the valid detection data to the output buffer at the valid index
    outputBoxes[validIndex] = float4(xMin, flippedYMin, boxWidth, flippedYMax - flippedYMin); // Store bounding box coordinates
    outputClasses[validIndex] = classIndex; // Store the predicted class index
    outputScores[validIndex] = maxClassScore; // Store the confidence score
}
